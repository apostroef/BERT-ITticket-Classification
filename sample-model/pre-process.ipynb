{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5725d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Library import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbbb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../translated_data.csv\")\n",
    "tiket_df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab85122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Pastikan Anda sudah memuat DataFrame bernama tiket_df\n",
    "# Jika Anda belum memuatnya, ganti baris di bawah ini dengan kode pemuatan data Anda.\n",
    "# Contoh: tiket_df = pd.read_csv(\"path/to/translated_data.csv\")\n",
    "\n",
    "# =========================================================\n",
    "# === MOHON GANTI NAMA KOLOM DI BAWAH SESUAI DATA ANDA ===\n",
    "# =========================================================\n",
    "\n",
    "# Kolom yang berisi teks/body tiket\n",
    "TEXT_COLUMN = \"body\"\n",
    "\n",
    "# Daftar kolom yang merupakan target klasifikasi multi-output Anda (misalnya Kategori, Prioritas)\n",
    "TARGET_COLUMNS = [\"type\", \"queue\", \"priority\"]\n",
    "# =========================================================\n",
    "\n",
    "if tiket_df.empty:\n",
    "    print(\"Error: DataFrame 'tiket_df' kosong atau belum dimuat.\")\n",
    "else:\n",
    "    # 1. Menghitung Jumlah Kata (Word Count) untuk Setiap Baris\n",
    "    # Menggunakan .astype(str) untuk menghindari error jika ada nilai non-string (misalnya NaN)\n",
    "    print(\"Langkah 1: Menghitung jumlah kata...\")\n",
    "    tiket_df[\"word_count\"] = (\n",
    "        tiket_df[TEXT_COLUMN].astype(str).apply(lambda x: len(x.split()))\n",
    "    )\n",
    "\n",
    "    p95_results = {}\n",
    "\n",
    "    # 2. Iterasi untuk Menghitung P95 di Setiap Kolom Target\n",
    "    print(\"\\nLangkah 2: Menghitung P95 Word Length per Kelas Target...\")\n",
    "    for target in TARGET_COLUMNS:\n",
    "        if target in tiket_df.columns and not tiket_df[target].isnull().all():\n",
    "\n",
    "            # Menghitung P95 (Quantile 0.95) dari word_count yang dikelompokkan berdasarkan kelas target\n",
    "            p95_series = (\n",
    "                tiket_df.groupby(target)[\"word_count\"]\n",
    "                .quantile(0.95)\n",
    "                .sort_values(ascending=False)\n",
    "            )\n",
    "            p95_results[target] = p95_series\n",
    "\n",
    "            print(f\"\\n--- P95 Word Length untuk Target: '{target}' ---\")\n",
    "            print(p95_series.to_string())\n",
    "            print(\"-\" * 50)\n",
    "        else:\n",
    "            print(f\"Peringatan: Kolom target '{target}' tidak ditemukan atau kosong.\")\n",
    "\n",
    "    # 3. Menentukan Max Length Rekomendasi\n",
    "    # Cari nilai P95 tertinggi dari semua kelas di semua target\n",
    "    max_p95 = 0\n",
    "    if p95_results:\n",
    "        all_p95_values = pd.concat(p95_results.values())\n",
    "        max_p95 = all_p95_values.max()\n",
    "\n",
    "    # Faktor konversi (Word ke Token: ~1.3) dan Margin (P95 ke P99)\n",
    "    # Kita gunakan faktor 1.5 untuk margin keamanan yang lebih besar (Word -> Token + Buffer)\n",
    "    RECOMMENDED_MAX_LENGTH = int(max_p95 * 1.5) if max_p95 > 0 else 128\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"               REKOMENDASI MAX_LENGTH\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Nilai P95 (Word Count) Tertinggi Ditemukan: {int(max_p95)} kata\")\n",
    "    print(\n",
    "        f\"Rekomendasi Max Length (Token) untuk BERT (P95 * 1.5 buffer): {RECOMMENDED_MAX_LENGTH} token\"\n",
    "    )\n",
    "    print(\n",
    "        \"\\nAnda harus menggunakan nilai ini (atau mendekatinya, mis. 256 atau 512) saat tokenisasi.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515514b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# your chosen max length (based on average words per ticket)\n",
    "encodings = tokenizer(\n",
    "    tiket_df[\"translated_body\"].astype(str).tolist(),  # list of texts to encode\n",
    "    padding=True,  # pad to max_length within the batch\n",
    "    truncation=True,  # truncate longer sequences\n",
    "    max_length=256,  # âœ… your parameter here\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "display(encodings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
